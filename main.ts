import { serve } from "https://deno.land/std@0.200.0/http/server.ts";
import { serveDir } from "https://deno.land/std@0.200.0/http/file_server.ts";

// --- è¾…åŠ©å‡½æ•°ï¼šç”¨äºç”Ÿæˆ OpenAI æ ¼å¼çš„é”™è¯¯å“åº” ---
function createOpenAIErrorResponse(message: string, statusCode = 500) {
    const errorPayload = { error: { message, type: "server_error" } };
    console.error("Replying with error:", JSON.stringify(errorPayload, null, 2));
    return new Response(JSON.stringify(errorPayload), {
        status: statusCode, headers: { 
            "Content-Type": "application/json", "Access-Control-Allow-Origin": "*",
        }
    });
}

// --- æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼šè°ƒç”¨ OpenRouter ---
async function callOpenRouter(prompt: string, images: string[], apiKey: string): Promise<string> {
    const contentPayload: any[] = [{ type: "text", text: prompt }];
    if (images && images.length > 0) {
        for (const imageUrl of images) {
            contentPayload.push({ type: "image_url", image_url: { url: imageUrl } });
        }
        if(contentPayload[0].text){
           contentPayload[0].text = `æ ¹æ®æˆ‘ä¸Šä¼ çš„è¿™ ${images.length} å¼ å›¾ç‰‡ï¼Œ${prompt}`;
        }
    }
    const openrouterPayload = {
        model: "google/gemini-2.5-flash-image-preview:free",
        messages: [{ role: "user", content: contentPayload }],
        stream: false
    };
    console.log("Sending payload to OpenRouter:", JSON.stringify(openrouterPayload, null, 2));
    const apiResponse = await fetch("https://openrouter.ai/api/v1/chat/completions", {
        method: "POST", headers: { "Authorization": `Bearer ${apiKey}`, "Content-Type": "application/json" },
        body: JSON.stringify(openrouterPayload)
    });
    if (!apiResponse.ok) {
        const errorBody = await apiResponse.text();
        console.error("OpenRouter API error:", errorBody);
        throw new Error(`OpenRouter API error: ${apiResponse.statusText} - ${errorBody}`);
    }
    const responseData = await apiResponse.json();
    console.log("OpenRouter Response:", JSON.stringify(responseData, null, 2));
    const message = responseData.choices?.[0]?.message;
    if (!message) { throw new Error("Invalid response from OpenRouter: No 'message' object."); }
    const messageContent = message.content || "";
    let imageUrl = '';
    if (messageContent.startsWith('data:image/')) { imageUrl = messageContent; }
    else if (message.images && message.images.length > 0 && message.images[0].image_url?.url) { imageUrl = message.images[0].image_url.url; }
    if (!imageUrl) { throw new Error("Could not extract a valid image URL from the OpenRouter API response."); }
    return imageUrl;
}

// --- ä¸»æœåŠ¡é€»è¾‘ ---
serve(async (req) => {
    const pathname = new URL(req.url).pathname;

    // CORS é¢„æ£€è¯·æ±‚å¤„ç†
    if (req.method === 'OPTIONS') { /* ... [ä»£ç ä¸å˜] */ }

    if (pathname === "/v1/chat/completions") {
        try {
            const openaiRequest = await req.json();
            const authHeader = req.headers.get("Authorization");
            if (!authHeader || !authHeader.startsWith("Bearer ")) { return createOpenAIErrorResponse("Authorization header missing", 401); }
            const openrouterApiKey = authHeader.substring(7);
            const userMessage = openaiRequest.messages?.find((m: any) => m.role === 'user');
            if (!userMessage || !userMessage.content) { return createOpenAIErrorResponse("No user message", 400); }
            let prompt = ""; const images: string[] = [];
            if (Array.isArray(userMessage.content)) {
                for (const part of userMessage.content) {
                    if (part.type === 'text') { prompt = part.text; } 
                    else if (part.type === 'image_url' && part.image_url?.url) { images.push(part.image_url.url); }
                }
            } else { prompt = userMessage.content as string; }
            if (!prompt) { return createOpenAIErrorResponse("Prompt is missing", 400); }
            
            const fullBase64Url = await callOpenRouter(prompt, images, openrouterApiKey);

            const stream = new ReadableStream({
                start(controller) {
                    const sendChunk = (data: object) => {
                        const chunkString = `data: ${JSON.stringify(data)}\n\n`;
                        controller.enqueue(new TextEncoder().encode(chunkString));
                    };

                    // ========================= ã€imageCallbacks.ts é€»è¾‘çº§ä¿®å¤ã€‘ =========================
                    // è¿™ä¸ªäº‹ä»¶æµç²¾ç¡®åœ°æ»¡è¶³äº† imageCallbacks.ts çš„ä¸¤æ­¥å¤„ç†é€»è¾‘

                    // --- ç¬¬ 1 æ­¥ï¼šå‘é€ IMAGE_CREATED ---
                    // è§¦å‘ onImageCreated å›è°ƒã€‚
                    // è¿™ä¼šåœ¨å‰ç«¯åˆ›å»ºä¸€ä¸ªçŠ¶æ€ä¸º PENDING çš„å›¾ç‰‡å—å ä½ç¬¦ï¼Œå¹¶æ˜¾ç¤ºå‡ºæ¥ã€‚
                    sendChunk({ type: 'IMAGE_CREATED' });
                    console.log("ğŸš€ Sent: IMAGE_CREATED (This will create the placeholder)");

                    // --- ç¬¬ 2 æ­¥ï¼šå‘é€ IMAGE_COMPLETE ---
                    // è§¦å‘ onImageGenerated å›è°ƒã€‚
                    // è¿™ä¼šæ‰¾åˆ°ç¬¬ä¸€æ­¥åˆ›å»ºçš„é‚£ä¸ªå ä½ç¬¦ï¼ŒæŠŠå›¾ç‰‡ URL å¡«è¿›å»ï¼Œå¹¶æŠŠçŠ¶æ€æ›´æ–°ä¸º SUCCESSã€‚
                    // æˆ‘ä»¬ç›´æ¥æ¨¡ä»¿ OpenAIApiClient.ts ä¸­ contentSource.images çš„ç»“æ„æ¥æ„é€  image å­—æ®µ
                    const imageDataPayload = {
                        images: [fullBase64Url] 
                    };
                    sendChunk({
                        type: 'IMAGE_COMPLETE',
                        image: imageDataPayload
                    });
                    console.log("ğŸ–¼ï¸ Sent: IMAGE_COMPLETE (This will fill the placeholder)");

                    // --- ç¬¬ 3 æ­¥ï¼šå‘é€ LLM_RESPONSE_COMPLETE ---
                    // ç»“æŸæ•´ä¸ªå“åº”æµï¼Œè®© Thunk å¯ä»¥åšæœ€åçš„æ¸…ç†å·¥ä½œã€‚
                    sendChunk({
                        type: 'LLM_RESPONSE_COMPLETE',
                        response: {
                            usage: { prompt_tokens: 50, completion_tokens: 700, total_tokens: 750 }
                        }
                    });
                    console.log("âœ… Sent: LLM_RESPONSE_COMPLETE");

                    // --- ç¬¬ 4 æ­¥ï¼šå‘é€æµç»“æŸæ ‡å¿— ---
                    const doneChunk = `data: [DONE]\n\n`;
                    controller.enqueue(new TextEncoder().encode(doneChunk));
                    console.log("ğŸ Sent: [DONE]");
                    
                    controller.close();
                    // ===============================================================
                }
            });

            return new Response(stream, {
                headers: {
                    "Content-Type": "text/event-stream", "Cache-Control": "no-cache", "Connection": "keep-alive",
                    "Access-Control-Allow-Origin": "*",
                },
            });
        } catch (error) {
            console.error("Error handling /v1/chat/completions request:", error);
            return createOpenAIErrorResponse(error.message);
        }
    }
    
    // ... [å…¶ä»–è·¯ç”±å¦‚ /generate å’Œé™æ€æ–‡ä»¶æœåŠ¡ä¿æŒä¸å˜] ...
    if (pathname === "/generate") { /* ... */ }
    return serveDir(req, { fsRoot: "static", urlRoot: "", showDirListing: true, enableCors: true });
});
