import { serve } from "https://deno.land/std@0.200.0/http/server.ts";
import { serveDir } from "https://deno.land/std@0.200.0/http/file_server.ts";

// --- è¾…åŠ©å‡½æ•°ï¼šç”¨äºç”Ÿæˆ OpenAI æ ¼å¼çš„é”™è¯¯å“åº” ---
function createOpenAIErrorResponse(message: string, statusCode = 500) {
    const errorPayload = {
        error: { message: message, type: "server_error" }
    };
    console.error("Replying with error:", JSON.stringify(errorPayload, null, 2));
    return new Response(JSON.stringify(errorPayload), {
        status: statusCode, headers: { "Content-Type": "application/json" }
    });
}

// --- æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼šè°ƒç”¨ OpenRouter (ä¿æŒä¸å˜) ---
async function callOpenRouter(prompt: string, images: string[], apiKey: string) {
    // ... è¿™éƒ¨åˆ†ä»£ç æ— éœ€æ”¹åŠ¨
    const contentPayload: any[] = [{ type: "text", text: prompt }];
    if (images && images.length > 0) {
        for (const imageUrl of images) {
            contentPayload.push({ type: "image_url", image_url: { url: imageUrl } });
        }
        if(contentPayload[0].text){
           contentPayload[0].text = `æ ¹æ®æˆ‘ä¸Šä¼ çš„è¿™ ${images.length} å¼ å›¾ç‰‡ï¼Œ${prompt}`;
        }
    }
    const openrouterPayload = {
        model: "google/gemini-2.5-flash-image-preview:free",
        messages: [{ role: "user", content: contentPayload }],
        stream: false
    };
    console.log("Sending payload to OpenRouter:", JSON.stringify(openrouterPayload, null, 2));
    const apiResponse = await fetch("https://openrouter.ai/api/v1/chat/completions", {
        method: "POST", headers: { "Authorization": `Bearer ${apiKey}`, "Content-Type": "application/json" },
        body: JSON.stringify(openrouterPayload)
    });
    if (!apiResponse.ok) {
        const errorBody = await apiResponse.text();
        console.error("OpenRouter API error:", errorBody);
        throw new Error(`OpenRouter API error: ${apiResponse.statusText} - ${errorBody}`);
    }
    const responseData = await apiResponse.json();
    console.log("OpenRouter Response:", JSON.stringify(responseData, null, 2));
    const message = responseData.choices?.[0]?.message;
    if (!message) {
        throw new Error("Invalid response from OpenRouter: No 'message' object.");
    }
    const messageContent = message.content || "";
    let imageUrl = '';
    if (messageContent.startsWith('data:image/')) {
        imageUrl = messageContent;
    }
    else if (message.images && message.images.length > 0 && message.images[0].image_url?.url) {
        imageUrl = message.images[0].image_url.url;
    }
    if (!imageUrl) {
        console.error("Could not extract image URL from OpenRouter response:", JSON.stringify(message, null, 2));
        throw new Error("Could not extract a valid image URL from the OpenRouter API response.");
    }
    return imageUrl;
}

// --- ä¸»æœåŠ¡é€»è¾‘ ---
serve(async (req) => {
    const pathname = new URL(req.url).pathname;

    // --- å…¼å®¹ OpenAI API çš„ç«¯ç‚¹ ---
    if (pathname === "/v1/chat/completions") {
        try {
            // --- å¢å¼ºæ—¥å¿— ---
            console.log("ğŸ Received Headers from Cherry Studio:", JSON.stringify(Object.fromEntries(req.headers.entries()), null, 2));
            const openaiRequest = await req.json();
            console.log("ğŸ“¦ Received Body from Cherry Studio:", JSON.stringify(openaiRequest, null, 2));

            const authHeader = req.headers.get("Authorization");
            if (!authHeader || !authHeader.startsWith("Bearer ")) {
                return createOpenAIErrorResponse("Authorization header is missing or invalid.", 401);
            }
            const openrouterApiKey = authHeader.substring(7);
            const userMessage = openaiRequest.messages?.find((m: any) => m.role === 'user');
            const requestedModel = openaiRequest.model || 'gpt-4o';

            if (!userMessage || !userMessage.content) {
                return createOpenAIErrorResponse("Invalid request: No user message found.", 400);
            }

            let prompt = "";
            const images: string[] = [];
            if (Array.isArray(userMessage.content)) {
                for (const part of userMessage.content) {
                    if (part.type === 'text') { prompt = part.text; } 
                    else if (part.type === 'image_url' && part.image_url?.url) { images.push(part.image_url.url); }
                }
            } else if (typeof userMessage.content === 'string') { prompt = userMessage.content; }

            if (!prompt) { return createOpenAIErrorResponse("Invalid request: Prompt text is missing.", 400); }

            const generatedImageUrl = await callOpenRouter(prompt, images, openrouterApiKey);

            // ========================= ã€æœ€ç»ˆä¿®å¤ã€‘ =========================
            const responsePayload = {
                id: `chatcmpl-${crypto.randomUUID()}`,
                object: "chat.completion",
                created: Math.floor(Date.now() / 1000),
                model: requestedModel,
                choices: [{
                    index: 0,
                    message: {
                        role: "assistant",
                        // 1. å¢åŠ ä¸€ä¸ªç©ºçš„ text éƒ¨åˆ†ï¼Œå¢å¼ºå…¼å®¹æ€§
                        content: [
                            { type: "text", text: "" },
                            { type: "image_url", image_url: { "url": generatedImageUrl } }
                        ]
                    },
                    finish_reason: "stop"
                }],
                // 2. ä¼ªé€ ä¸€ä¸ªçœ‹èµ·æ¥çœŸå®çš„ usage å¯¹è±¡
                usage: {
                    prompt_tokens: 50,      // ä¼ªé€ å€¼
                    completion_tokens: 700, // ä¼ªé€ å€¼
                    total_tokens: 750       // ä¼ªé€ å€¼
                }
            };
            // ===============================================================

            console.log("âœ… Sending final payload to Cherry Studio:", JSON.stringify(responsePayload, null, 2));

            return new Response(JSON.stringify(responsePayload), {
                headers: { "Content-Type": "application/json" },
            });
        } catch (error) {
            console.error("Error handling /v1/chat/completions request:", error);
            return createOpenAIErrorResponse(error.message);
        }
    }
    
    // --- åŸæ¥çš„ Web UI åç«¯é€»è¾‘ (ä¿æŒä¸å˜) ---
    if (pathname === "/generate") { /* ... */ }

    // --- é™æ€æ–‡ä»¶æœåŠ¡ (ä¿æŒä¸å˜) ---
    return serveDir(req, { fsRoot: "static", urlRoot: "" });
});
